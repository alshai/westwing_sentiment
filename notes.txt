parsing:
for each line
line[1] - the range of bytes, so extract the phrase and store that in the dictionary
line[2] - agent, only care about agents
line[3] - extract only the attributes that we care about

{ phrase (length limited by n-gram count):
	agent: ""
	attrs: {}
}

training:
n-gram HMM. 
train using this set
test on one or two episodes of The West Wing
evaluate against our manual labeling

Stanford data from: http://nlp.stanford.edu/sentiment/code.html
Congressional data: http://www.cs.cornell.edu/home/llee/data/convote.html

accuracies with 0.75 weight for neutral:
10000 max_ent vs gold: 0.846763540291
10000 bow vs gold: 0.71499339498
20000 max_ent vs gold: 0.846763540291
20000 bow vs gold: 0.71499339498
30000 max_ent vs gold: 0.846763540291
30000 bow vs gold: 0.71499339498
40000 max_ent vs gold: 0.846763540291
40000 bow vs gold: 0.71499339498
50000 max_ent vs gold: 0.846763540291
50000 bow vs gold: 0.71499339498
60000 max_ent vs gold: 0.846763540291
60000 bow vs gold: 0.71499339498
70000 max_ent vs gold: 0.808784676354
70000 bow vs gold: 0.71499339498
80000 max_ent vs gold: 0.733817701453
80000 bow vs gold: 0.71499339498
90000 max_ent vs gold: 0.653896961691
90000 bow vs gold: 0.71499339498
100000 max_ent vs gold: 0.643989431968
100000 bow vs gold: 0.71499339498
110000 max_ent vs gold: 0.634081902246
110000 bow vs gold: 0.71499339498
120000 max_ent vs gold: 0.617239101717
120000 bow vs gold: 0.71499339498

Some reading on features: http://www.cs.columbia.edu/~julia/papers/Agarwaletal11.pdf


accuracies with neutral=0:
10000 max_ent vs gold: 0.387054161162
10000 bow vs gold: 0.391017173052
20000 max_ent vs gold: 0.387054161162
20000 bow vs gold: 0.391017173052
30000 max_ent vs gold: 0.387054161162
30000 bow vs gold: 0.391017173052
40000 max_ent vs gold: 0.387054161162
40000 bow vs gold: 0.391017173052
50000 max_ent vs gold: 0.387054161162
50000 bow vs gold: 0.391017173052
60000 max_ent vs gold: 0.387054161162
60000 bow vs gold: 0.391017173052
70000 max_ent vs gold: 0.38177014531
70000 bow vs gold: 0.391017173052
80000 max_ent vs gold: 0.406869220608
80000 bow vs gold: 0.391017173052
90000 max_ent vs gold: 0.384412153236
90000 bow vs gold: 0.391017173052
100000 max_ent vs gold: 0.404227212682
100000 bow vs gold: 0.391017173052
110000 max_ent vs gold: 0.392338177015
110000 bow vs gold: 0.391017173052
120000 max_ent vs gold: 0.392338177015
120000 bow vs gold: 0.391017173052


select lines:

 # josh was joking around wiht Donna here
  {'bow_score': 'neutral',
   'character': 'JOSH',
   'gold_score': 'positive',
   'maxent_score': 'negative',
   'text': 'You should be nice to me. I could be dead you know.'},

# Mandy is pretty mad at Josh
  {'bow_score': 'neutral',
   'character': 'MANDY',
   'gold_score': 'negative',
   'maxent_score': 'negative',
   'text': "This isn't funny, Josh."},

# sarcasm
  {'bow_score': 'positive',
   'character': 'C.J.',
   'gold_score': 'negative',
   'maxent_score': 'negative',
   'text': "Yeah. I can't believe my psychic didn't tell me, Toby. Rest
    assured, I'm gonna get my twenty bucks back."},

# another case of sarcasm
  {'bow_score': 'negative',
   'character': 'JOSH',
   'gold_score': 'positive',
   'maxent_score': 'negative',
   'text': "[laughs] I was interrogating this intern from the Legislative
    Liaison's Office, and she broke down crying while telling me about the bong
    she had made out of an eggplant."},

