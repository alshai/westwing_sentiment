parsing:
for each line
line[1] - the range of bytes, so extract the phrase and store that in the dictionary
line[2] - agent, only care about agents
line[3] - extract only the attributes that we care about

{ phrase (length limited by n-gram count):
	agent: ""
	attrs: {}
}

training:
n-gram HMM. 
train using this set
test on one or two episodes of The West Wing
evaluate against our manual labeling

Stanford data from: http://nlp.stanford.edu/sentiment/code.html
Congressional data: http://www.cs.cornell.edu/home/llee/data/convote.html

accuracies:
10000 max_ent vs gold: 0.846763540291
10000 bow vs gold: 0.71499339498
20000 max_ent vs gold: 0.846763540291
20000 bow vs gold: 0.71499339498
30000 max_ent vs gold: 0.846763540291
30000 bow vs gold: 0.71499339498
40000 max_ent vs gold: 0.846763540291
40000 bow vs gold: 0.71499339498
50000 max_ent vs gold: 0.846763540291
50000 bow vs gold: 0.71499339498
60000 max_ent vs gold: 0.846763540291
60000 bow vs gold: 0.71499339498
70000 max_ent vs gold: 0.808784676354
70000 bow vs gold: 0.71499339498
80000 max_ent vs gold: 0.733817701453
80000 bow vs gold: 0.71499339498
90000 max_ent vs gold: 0.653896961691
90000 bow vs gold: 0.71499339498
100000 max_ent vs gold: 0.643989431968
100000 bow vs gold: 0.71499339498
110000 max_ent vs gold: 0.634081902246
110000 bow vs gold: 0.71499339498
120000 max_ent vs gold: 0.617239101717
120000 bow vs gold: 0.71499339498

Some reading on features: http://www.cs.columbia.edu/~julia/papers/Agarwaletal11.pdf
